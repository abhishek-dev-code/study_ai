ğŸ“˜ Study Assistant AI

A lightweight personal study companion built with FastAPI + Google Gemini API

ğŸš€ Overview

Study Assistant AI is a minimal, production-ready study helper built in Python.
It answers questions, plans study tasks, and maintains a small personalized learning memory.

Project goals:

Clean backend design

Lightweight and fast

Modular agents

Real deployable architecture (Docker + Cloud Run)

ğŸ§  Features

âœ” Doubt solving (concept explanations)
âœ” Study planning assistant
âœ” Resource finder (articles, videos, references)
âœ” Memory-powered personalization
âœ” API endpoint for frontend integration
âœ” Google Gemini 2.5 Flash model support
âœ” Docker + Cloud Run deployable

ğŸ— Tech Stack

Python 3.10+
FastAPI
Google Gemini (Generative AI)
Uvicorn
Docker
Cloud Run (optional deploy)

ğŸ“‚ Project Structure
study_ai/
â”œâ”€â”€ main.py
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ study_assistant.py
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ doubt_solver.py
â”‚   â”œâ”€â”€ resource_finder.py
â”‚   â””â”€â”€ study_planner.py
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ search_tool.py
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ user_profile.json
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ user_profile/
â”‚   â”œâ”€â”€ history.json
â”‚   â””â”€â”€ history.py
â”‚
â””â”€â”€ deployment/
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ cloudrun.yaml

ğŸ“¡ API Endpoints
âœ“ Status Check

GET /

{ 
  "message": "Study Assistant is running successfully!" 
}

âœ“ Ask a question

POST /ask
Request:

{ "query": "What is Newton's second law?" }


Response:

{
  "answer": "Force equals mass times acceleration..."
}

ğŸ”‘ Setup Instructions

1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Set your Google Gemini API Key
.env file create kare:

GOOGLE_API_KEY=your_key_here

(.env.example already provided)

3ï¸âƒ£ Run locally
python -m uvicorn main:app --reload

ğŸ³ Docker Support
Build
docker build -t study-assistant .

Run
docker run -p 8000:8000 study-assistant

â˜ Deploy on Cloud Run
gcloud run deploy study-assistant \
  --source . \
  --region asia-south1 \
  --platform managed \
  --allow-unauthenticated

ğŸ” Why this project?

I built this project to explore:

How LLMs can be integrated into real backend services

Practical prompt engineering

Agent-based modular design

Deploying lightweight AI assistants in the cloud

It works well as:

A personal assistant

A starter template for AI agents

A base for larger study applications

ğŸ“œ License

MIT License

ğŸ™Œ Acknowledgements

Google Gemini API

FastAPI community